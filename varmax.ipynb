{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX, VARMAXResults\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_weather_df = pd.read_csv('data/region/vietnam/interpolated_weather.csv', index_col=0, parse_dates=True)\n",
    "interpolated_air_df = pd.read_csv('data/region/vietnam/interpolated_air.csv', index_col=0, parse_dates=True)\n",
    "interpolated_air_df.drop(columns='aqi', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_train, air_test = interpolated_air_df.loc[:'2023-12-31 23:00:00'], interpolated_air_df.loc['2024-01-01 00:00:00':]\n",
    "weather_train, weather_test = interpolated_weather_df.loc[:'2023-12-31 23:00:00'], interpolated_weather_df.loc['2024-01-01 00:00:00':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_scaler = StandardScaler()\n",
    "weather_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_normalized = air_scaler.fit_transform(air_train.iloc[:,1:].to_numpy())\n",
    "weather_normalized = weather_scaler.fit_transform(weather_train.iloc[:,1:].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_normalized = pd.DataFrame(air_normalized, columns=air_train.columns[1:], index=air_train.index)\n",
    "weather_normalized = pd.DataFrame(weather_normalized, columns=weather_train.columns[1:], index=weather_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _exog_gen(exog, partitions):\n",
    "    \"\"\"partitions exog data\"\"\"\n",
    "\n",
    "    n_exog = exog.shape[0]\n",
    "    n_part = np.ceil(n_exog / partitions)\n",
    "\n",
    "    ii = 0\n",
    "    while ii < n_exog:\n",
    "        jj = int(min(ii + n_part, n_exog))\n",
    "        yield exog.iloc[ii:jj, :]\n",
    "        ii += int(n_part)\n",
    "\n",
    "\n",
    "def _endog_gen(endog, partitions):\n",
    "    \"\"\"partitions endog data\"\"\"\n",
    "\n",
    "    n_endog = endog.shape[0]\n",
    "    n_part = np.ceil(n_endog / partitions)\n",
    "\n",
    "    ii = 0\n",
    "    while ii < n_endog:\n",
    "        jj = int(min(ii + n_part, n_endog))\n",
    "        yield endog.iloc[ii:jj]\n",
    "        ii += int(n_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_normalized = pd.concat([air_train['province'] ,weather_normalized],axis=1)\n",
    "air_normalized = pd.concat([air_train['province'] ,air_normalized],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_by_province = weather_normalized.reset_index().sort_values(by=['province', 'time']).set_index('time')\n",
    "air_by_province = air_normalized.reset_index().sort_values(by=['province', 'time']).set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VARMAX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed_estimation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     DistributedModel,\n\u001b[0;32m      3\u001b[0m     _est_unregularized_naive,\n\u001b[0;32m      4\u001b[0m     _join_naive\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m varmax_distributed \u001b[38;5;241m=\u001b[39m DistributedModel(partitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m63\u001b[39m, model_class \u001b[38;5;241m=\u001b[39m \u001b[43mVARMAX\u001b[49m, init_kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrend\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m'\u001b[39m}, results_class\u001b[38;5;241m=\u001b[39mVARMAXResults, estimation_method\u001b[38;5;241m=\u001b[39m_est_unregularized_naive, join_method\u001b[38;5;241m=\u001b[39m_join_naive)\n\u001b[0;32m     10\u001b[0m varmax_fit \u001b[38;5;241m=\u001b[39m varmax_distributed\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mzip\u001b[39m(_endog_gen(air_by_province\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;241m63\u001b[39m), _exog_gen(weather_by_province\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;241m63\u001b[39m)),\n\u001b[0;32m     12\u001b[0m     fit_kwds\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.2\u001b[39m},\n\u001b[0;32m     13\u001b[0m     parallel_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoblib\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VARMAX' is not defined"
     ]
    }
   ],
   "source": [
    "from statsmodels.base.distributed_estimation import (\n",
    "    DistributedModel,\n",
    "    _est_unregularized_naive,\n",
    "    _join_naive\n",
    ")\n",
    "\n",
    "\n",
    "varmax_distributed = DistributedModel(partitions = 63, model_class = VARMAX, init_kwds = {'order':(0,2), 'trend':'ct'}, results_class=VARMAXResults, estimation_method=_est_unregularized_naive, join_method=_join_naive)\n",
    "\n",
    "varmax_fit = varmax_distributed.fit(\n",
    "    zip(_endog_gen(air_by_province.iloc[:,1:], 63), _exog_gen(weather_by_province.iloc[:,1:], 63)),\n",
    "    fit_kwds={'maxiter':1, 'method':'lbfgs', \"alpha\": 0.2},\n",
    "    parallel_method='joblib' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varmax_fit.save('varmax.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
